description: test run for natural instructions
target:
  service: amlk8s
  name: itphyperdgx2cl1
  vc: hai3
  # service: amlk8s
  # name: itpscusv100cl
  # vc: resrchvc
  # Standard_NC24rs_v2
  # service: amlk8s
  # name: itpeusp100cl
  # vc: resrchvc

environment:
  # https://phillytools.azurewebsites.net/master/advanced/5_customizing_dockers.html
  # image: huggingface/transformers-pytorch-gpu:latest
  # registry: registry.hub.docker.com   # this is the default
  image: pytorch/pytorch:1.9.0-cuda11.1-cudnn8-devel
  # image: pytorch/pytorch:1.4-cuda10.1-cudnn7-devel
  # registry: docker.io # any public registry can be specified here
  image_setup:
  - pip install transformers
  - pip install datasets
  - pip install ruamel.yaml==0.16 --disable-pip-version-check
  - pip install rouge_score
  - pip install accelerate
  - pip install py7zr
  - pip install rouge-metric


storage:
  data:
    storage_account_name: budebsmartreplymltl
    container_name: amulet
    mount_dir: /mnt/amulet


code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: /mnt/Repos/LIT/Projects/NLGNI/

data:
  local_dir: /mnt/Data/natural_instructions/
  remote_dir: Data


jobs:
- name: test_amlk8
  sku: G1
  command:
  - python data/natural_instructions/train.py --output_dir $$AMLT_DATA_DIR/models/natural_instructions/
    --dataset_folder $$AMLT_DATA_DIR/natural_instructions/
    --cache_dir $$AMLT_DATA_DIR/model_cache_pt/ --overwrite_cache True
    --model_name_or_path facebook/bart-base
    --tokenizer_name facebook/bart-base
    --dataset_name natural_instructions
    --do_train --do_eval --do_predict
    --num_train_epochs 40
    --learning_rate 5e-5 --warmup_steps 0
    --per_device_train_batch_size 24 --per_device_eval_batch_size 24
    --max_source_length 512 --max_target_length 64
    --predict_with_generate
    --overwrite_output_dir True
    --add_task_summary True --add_instruction True --add_positive_examples True --add_negative_examples False --add_explanations True --num_examples_in_instruction 1
    --num_train_instances_per_task 100 --train_test_split_mode random_tasks_zero_shot
    --metric_for_best_model rouge-2-f --evaluation_strategy steps --eval_steps 500 --logging_steps 100
    --load_best_model_at_end True --save_steps 100000 --max_eval_samples 10000
    --disable_tqdm True


  #   # --max_train_samples 10000 --max_eval_samples 10000
  # submit_args:
  #   container_args:
  #       shm_size: 64g
