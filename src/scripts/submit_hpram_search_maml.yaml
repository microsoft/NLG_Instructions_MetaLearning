description: HP Search run for natural instructions Meta
target:
  # service: amlk8s
  # name: itphyperdgx2cl1
  # vc: hai3
  # Standard_NC24rs_v2
  # service: amlk8s
  # name: itpeusp100cl
  # vc: resrchvc
 
  service: amlk8s
  name: itplabrr1cl1
  vc: resrchvc
environment:
  # https://phillytools.azurewebsites.net/master/advanced/5_customizing_dockers.html
  # image: huggingface/transformers-pytorch-gpu:latest
  # registry: registry.hub.docker.com   # this is the default
  image: pytorch/pytorch:1.9.0-cuda11.1-cudnn8-devel
  # image: pytorch/pytorch:1.4-cuda10.1-cudnn7-devel
  # registry: docker.io # any public registry can be specified here
  image_setup:
  - pip install transformers==4.11.0
  - pip install datasets
  - pip install ruamel.yaml==0.16 --disable-pip-version-check
  - pip install rouge_score
  - pip install accelerate
  - pip install py7zr
  - pip install rouge-metric
  - pip install learn2learn
  - pip install higher

storage:
  data:
    storage_account_name: budebsmartreplymltl
    container_name: amulet
    mount_dir: /mnt/amulet


code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file

  local_dir: /mnt/Repos/LIT/Projects/NLGNI/

data:
  local_dir: /mnt/Data/natural_instructions_v2.5/
  remote_dir: Data


    #   --use_train_dataset_for_eval True
search:
  job_template:
    name: HPsearch_{experiment_name:s}_{add_instruction}_{add_positive}_{add_explanation}
    sku: G1
    command:
    - python $$AMLT_CODE_DIR/data/natural_instructions_dataset/train.py
      --output_dir $$AMLT_DATA_DIR/models/natural_instructions_v2.5/itplabrr1cl1/MAML/BBase_{train_task_list}_20_{add_instruction}_{add_positive}_{add_explanation}_{train_task_list}_{lr}_{num_train_instances}_{ga_steps}_{wa_steps}_{inner_lr}_{inner_steps}_{inner_batch}_{inner_tasks}_{2nd_ord}_{multi_step}_6_16_22
      --model_name_or_path {model_name} --tokenizer_name {model_name}
      --dataset_name natural_instructions_v2.5 --dataset_folder $$AMLT_DATA_DIR/natural_instructions_v2.5/ --overwrite_output_dir True
      --cache_dir $$AMLT_DATA_DIR/model_cache_pt/ --overwrite_cache True
      --do_train --do_eval --do_predict --predict_with_generate
      --max_source_length 1024 --max_target_length 128 --decode_max_length 128
      --disable_tqdm True --save_checkpoints True --resume_from_checkpoint True
      --num_train_epochs {epochs} --eval_steps 400  --logging_steps 20  --save_steps 400 
      --load_best_model_at_end False --evaluation_strategy steps --metric_for_best_model rouge-l-f --multi_ref_mode best
      --log_task_level_metrics True --show_example_predictions 0 --log_level warning
      --per_device_train_batch_size 1 --per_device_eval_batch_size 8
      --use_train_tasks_list {train_task_list} --use_exclude_tasks_list {exclude_task_list}
      --use_test_tasks_list {test_task_list} --use_eval_tasks_list {eval_task_list}
      --train_test_split_mode random_tasks_k_shot --filter_dataset_by_length True
      --num_kshot_train_instances_per_task {num_kshot_train_instances}  
      --num_train_instances_per_task {num_train_instances} --num_test_instances_per_task 50 --num_eval_instances_per_task 100
      --use_train_dataset_for_eval True
      --adafactor True --fp16 False --lr_scheduler_type linear --gradient_checkpointing
      --learning_rate {lr} --warmup_steps {wa_steps} --gradient_accumulation_steps {ga_steps} --lr_scheduler_type linear
      --add_category False --add_task_summary False --add_instruction {add_instruction} --add_positive_examples {add_positive}
      --add_negative_examples False --add_explanations {add_explanation}  --num_examples_in_instruction {num_examples} --prepend_inst_in_enc_or_dec encoder
      --filter_sequences_by_len_diff_from_ref False --pred_ref_diff_tolerance 1.0
      --train_loop_opt_type maml
      --task_sampling_mode uniform --target_task_sampling_rate_increase 0.000000
      --inner_loop_learning_rate {inner_lr} --max_grad_norm_meta 1.0 --use_second_order_gradients {2nd_ord} 
      --use_multi_step_loss_optimization {multi_step}  --multi_step_loss_num_steps 5000
      --num_inner_training_steps_per_iter {inner_steps} --task_batch_size_per_iter {inner_batch}  --num_tasks_per_iter {inner_tasks}
      --use_meta_sgd {meta_sgd} --meta_sgd_per_param_per_layer False

  max_trials: 16
  parallel_trials: 16
  max_duration_hours: 120
  metrics: # optimization objective. Required for bayesian sampling and early_termination, ignored otherwise
    - name: eval_rouge-l-f
      goal: maximize
  sampling: grid
  params:
    - name: model_name
      values: choice("facebook/bart-base")
    - name: num_train_instances
      values: choice(100)
    - name: epochs
      values: choice(20)
    - name: ga_steps
      values: choice(10)
    - name: lr
      values: choice(0.00001)
    - name: inner_lr
      values: choice(0.0001)
    - name: inner_steps
      values: choice(3)
    - name: inner_batch
      values: choice(10)
    - name: inner_tasks
      values: choice(2)
    - name: 2nd_ord
      values: choice("False")
    - name: multi_step
      values: choice("False")
    - name: meta_sgd
      values: choice("False")
    - name: wa_steps
      values: choice(500)
    - name: num_kshot_train_instances
      values: choice(0)
    - name: add_instruction
      values: choice("True", "False")
    - name: add_positive
      values: choice("True", "False")
    - name: add_explanation
      values: choice("False")
    - name: num_examples
      values: choice(1)
    - name: train_task_list
      values: choice("False")
    - name: test_task_list
      values: choice("False")
    - name: eval_task_list
      values: choice("TEST_TASKS_LIST_SUMM_TITLE")
    - name: exclude_task_list
      values: choice("EXCLUDE_TASKS_LIST_SUMM_TITLE")